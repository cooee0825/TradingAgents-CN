#!/usr/bin/env python3
"""
ç®€å•æµ‹è¯•Redditè‚¡ç¥¨åˆ†æåŠŸèƒ½

æ­¤è„šæœ¬ç”¨äºå¿«é€Ÿæµ‹è¯•æ–°å¼€å‘çš„Redditè‚¡ç¥¨çƒ­åº¦åˆ†æåŠŸèƒ½æ˜¯å¦æ­£å¸¸å·¥ä½œã€‚
"""

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))


def test_imports():
    """æµ‹è¯•å¯¼å…¥æ˜¯å¦æ­£å¸¸"""
    print("ğŸ§ª æµ‹è¯•1: æ£€æŸ¥å¯¼å…¥...")
    try:
        from tradingagents.dataflows.reddit_utils import (
            StockPopularityAnalyzer,
            analyze_stock_popularity,
            generate_reddit_stock_ranking,
            STOCK_SUBREDDITS,
            SUBREDDIT_WEIGHTS,
            ticker_to_company,
        )

        print("âœ… æ‰€æœ‰å¯¼å…¥æˆåŠŸ")
        return True
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False


def test_basic_functionality():
    """æµ‹è¯•åŸºç¡€åŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•2: æ£€æŸ¥åŸºç¡€åŠŸèƒ½...")

    try:
        from tradingagents.dataflows.reddit_utils import StockPopularityAnalyzer

        # åˆ›å»ºåˆ†æå™¨å®ä¾‹
        analyzer = StockPopularityAnalyzer()
        print("âœ… åˆ†æå™¨åˆ›å»ºæˆåŠŸ")

        # æµ‹è¯•å…³é”®è¯ç”Ÿæˆ
        keywords = analyzer.generate_stock_keywords("AAPL")
        print(f"âœ… å…³é”®è¯ç”ŸæˆæˆåŠŸ: {keywords[:3]}...")

        # æµ‹è¯•æ•°æ®ç›®å½•
        print(f"âœ… æ•°æ®ç›®å½•è®¾ç½®: {analyzer.data_dir}")

        return True

    except Exception as e:
        print(f"âŒ åŸºç¡€åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_configuration():
    """æµ‹è¯•é…ç½®æ˜¯å¦æ­£ç¡®"""
    print("\nğŸ§ª æµ‹è¯•3: æ£€æŸ¥é…ç½®...")

    try:
        from tradingagents.dataflows.reddit_utils import (
            STOCK_SUBREDDITS,
            SUBREDDIT_WEIGHTS,
            ticker_to_company,
        )

        print(f"âœ… è‚¡ç¥¨subreddité…ç½®: {len(STOCK_SUBREDDITS)} ä¸ª")
        print(f"   - {', '.join(STOCK_SUBREDDITS)}")

        print(f"âœ… subredditæƒé‡é…ç½®: {len(SUBREDDIT_WEIGHTS)} ä¸ª")
        for name, weight in SUBREDDIT_WEIGHTS.items():
            print(f"   - {name}: {weight}")

        print(f"âœ… è‚¡ç¥¨æ˜ å°„è¡¨: {len(ticker_to_company)} åªè‚¡ç¥¨")
        print(f"   - ç¤ºä¾‹: {list(ticker_to_company.items())[:3]}")

        return True

    except Exception as e:
        print(f"âŒ é…ç½®æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_data_availability():
    """æµ‹è¯•æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    print("\nğŸ§ª æµ‹è¯•4: æ£€æŸ¥æ•°æ®å¯ç”¨æ€§...")

    data_dir = Path("data/reddit_data/company_news")

    if not data_dir.exists():
        print("âš ï¸ Redditæ•°æ®ç›®å½•ä¸å­˜åœ¨")
        print(
            "è¯·å…ˆè¿è¡Œ: python -m tradingagents.dataflows.reddit_utils --category company_news"
        )
        return False

    # æ£€æŸ¥å„ä¸ªsubredditçš„æ•°æ®æ–‡ä»¶
    from tradingagents.dataflows.reddit_utils import STOCK_SUBREDDITS

    existing_files = []
    missing_files = []

    for subreddit in STOCK_SUBREDDITS:
        file_path = data_dir / f"{subreddit}.jsonl"
        if file_path.exists():
            existing_files.append(subreddit)
        else:
            missing_files.append(subreddit)

    print(f"âœ… æ‰¾åˆ°æ•°æ®æ–‡ä»¶: {len(existing_files)} ä¸ª")
    for subreddit in existing_files:
        file_path = data_dir / f"{subreddit}.jsonl"
        file_size = file_path.stat().st_size / 1024  # KB
        print(f"   - r/{subreddit}: {file_size:.1f}KB")

    if missing_files:
        print(f"âš ï¸ ç¼ºå°‘æ•°æ®æ–‡ä»¶: {len(missing_files)} ä¸ª")
        for subreddit in missing_files:
            print(f"   - r/{subreddit}")

    return len(existing_files) > 0


def test_simple_analysis():
    """æµ‹è¯•ç®€å•åˆ†æåŠŸèƒ½"""
    print("\nğŸ§ª æµ‹è¯•5: ç®€å•åˆ†ææµ‹è¯•...")

    try:
        from tradingagents.dataflows.reddit_utils import analyze_stock_popularity

        # å°è¯•åˆ†æAAPLï¼ˆå¦‚æœæ•°æ®å­˜åœ¨ï¼‰
        result = analyze_stock_popularity(
            ticker="AAPL",
            days_back=30,  # å¢åŠ å¤©æ•°èŒƒå›´
            min_relevance=0.05,  # é™ä½ç›¸å…³åº¦è¦æ±‚
        )

        print(f"âœ… AAPLåˆ†ææˆåŠŸ:")
        print(f"   - æåŠæ¬¡æ•°: {result['total_mentions']}")
        print(f"   - æ€»çƒ­åº¦: {result['total_popularity_score']:.2f}")
        print(f"   - å…³é”®è¯: {', '.join(result['keywords'][:3])}")

        if result["total_mentions"] == 0:
            print("âš ï¸ æœªæ‰¾åˆ°ç›¸å…³è®¨è®ºï¼Œè¿™å¯èƒ½æ˜¯æ­£å¸¸çš„")
            print("   å»ºè®®å¢åŠ days_backå‚æ•°æˆ–é™ä½min_relevanceé˜ˆå€¼")

        return True

    except Exception as e:
        print(f"âŒ ç®€å•åˆ†ææµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ” Redditè‚¡ç¥¨åˆ†æåŠŸèƒ½æµ‹è¯•")
    print("=" * 50)

    tests = [
        test_imports,
        test_basic_functionality,
        test_configuration,
        test_data_availability,
        test_simple_analysis,
    ]

    passed = 0
    total = len(tests)

    for test_func in tests:
        try:
            if test_func():
                passed += 1
        except Exception as e:
            print(f"âŒ æµ‹è¯•å¼‚å¸¸: {e}")

    print(f"\nğŸ“Š æµ‹è¯•ç»“æœ: {passed}/{total} é€šè¿‡")

    if passed == total:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå¯ä»¥ä½¿ç”¨ã€‚")
        print("\nğŸ’¡ ä¸‹ä¸€æ­¥å»ºè®®:")
        print("1. è¿è¡Œæ¼”ç¤ºè„šæœ¬: python examples/reddit_stock_analysis_demo.py")
        print("2. ä¸‹è½½æœ€æ–°æ•°æ®: python -m tradingagents.dataflows.reddit_utils")
        print("3. åœ¨ä½ çš„é¡¹ç›®ä¸­ä½¿ç”¨APIå‡½æ•°")
    else:
        print("âš ï¸ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®å’Œæ•°æ®ã€‚")
        if passed >= 3:
            print("åŸºç¡€åŠŸèƒ½æ­£å¸¸ï¼Œä¸»è¦æ˜¯æ•°æ®é—®é¢˜ã€‚")

    return 0 if passed == total else 1


if __name__ == "__main__":
    sys.exit(main())
